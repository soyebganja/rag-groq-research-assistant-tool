# Research Assistance Tool (RAT)

A powerful **AI-powered Research Assistance Tool** that lets you **ingest URLs and PDFs, store them in a vector database, and query them using natural language**.  
This tool uses **GROQ LLM** with **LangChain** to provide **fast, accurate, and context-aware responses**.

**Live Demo Link**: [RAG-GROQ-Research-Assistant-Tool](https://rag-groq-research-assistant-tool-hvcyd5qpjwhsa2uki8yyo9.streamlit.app/)
<img width="1284" height="690" alt="image" src="https://github.com/user-attachments/assets/0bbb0508-5942-447b-bdb7-9b2f10d89105" />

---

## ğŸš€ Features

- **URL & PDF ingestion**  
  Upload research papers, articles, and documents to build your knowledge base.
  
- **Vector Store for Search**  
  Uses **FAISS** for fast semantic search.
  
- **GROQ LLM-powered Q&A**  
  Ask natural language questions and get precise, context-rich answers.
  
- **Web UI via Streamlit**  
  Simple, interactive interface for ingestion and querying.
  
- **Chunked Data Processing**  
  Splits documents into meaningful chunks for better retrieval.

---

## ğŸ›  Tech Stack

- **[Python 3.10+]**
- **[LangChain](https://www.langchain.com/)** â€“ Orchestrating ingestion, chunking, and retrieval  
- **[FAISS](https://github.com/facebookresearch/faiss)** â€“ Efficient vector similarity search  
- **[GROQ LLM](https://groq.com/)** â€“ High-speed inference with Llama3 models  
- **[Streamlit](https://streamlit.io/)** â€“ User interface for easy interaction  
- **[PyPDF2](https://pypi.org/project/pypdf2/)** â€“ PDF parsing and text extraction  

---

# LangChain + GROQ + Streamlit: LLM App

A simple yet powerful LLM (Large Language Model) app built with **LangChain**, **GROQ API**, and **Streamlit**. This project allows you to interact with LLMs using GROQ as the backend, all through a clean Streamlit web interface.

---

# GROQ RAG Application

A Retrieval-Augmented Generation (RAG) application powered by the **GROQ LLM** and **LangChain**, designed to enable ultra-fast, intelligent responses from your own knowledge base. This project uses **GROQâ€™s blazing-fast inference** and **vector search** to deliver accurate, context-aware answers.

---

## ğŸš€ Features

- **GROQ LLM Integration** â€“ Ultra-low latency responses using the GROQ API.
- **LangChain Framework** â€“ Manages the RAG pipeline for seamless retrieval + generation.
- **PDF/Text Data Loading** â€“ Upload and process your documents easily.
- **FAISS / Chroma Vector Store** â€“ For efficient embedding storage and semantic search.
- **Streamlit Interface** â€“ Simple, clean UI for interacting with the chatbot.
- **Environment Variables** â€“ API keys and configs stored securely via `.env`.

---

## ğŸ“‚ Project Structure

```
groq-rag-app/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (not committed to Git)
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ data/                  # Folder for uploaded documents
â””â”€â”€ utils.py
```

---

## ğŸ› ï¸ Installation

1ï¸âƒ£ **Clone the repository**
```bash
git clone https://github.com/<your-username>/groq-rag-app.git
cd groq-rag-app
```

2ï¸âƒ£ **Create and activate a virtual environment**
```bash
python -m venv venv
source venv/bin/activate       # Mac/Linux
venv\Scripts\activate          # Windows
```

3ï¸âƒ£ **Install dependencies**
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Set up environment variables**

Create a `.env` file in the root directory and add:
```
GROQ_API_KEY=your_groq_api_key_here
```

---

## â–¶ï¸ Running the App

```bash
streamlit run app.py
```

Once running, open your browser at:
```
http://localhost:8501
```

---

## ğŸ“– How It Works

1. **Load Documents** â€“ PDF/Text files are loaded and split into chunks.
2. **Embed Documents** â€“ GROQ-compatible embeddings are generated and stored in a vector DB.
3. **Retrieve Context** â€“ Based on your query, relevant document chunks are retrieved.
4. **Generate Answer** â€“ GROQ LLM generates a contextual, accurate response.

---

## ğŸ“¦ Dependencies

- **Python** 3.9+
- **LangChain**
- **GROQ API**
- **FAISS / Chroma**
- **Streamlit**
- **dotenv**

Install them with:
```bash
pip install -r requirements.txt
```

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a new branch (`feature/my-feature`)
3. Commit changes (`git commit -m 'Add new feature'`)
4. Push to the branch (`git push origin feature/my-feature`)
5. Create a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ“§ Contact

**Author:** Soyeb Ganja 
**Email:** soyeb.ganja@gmail.com
**Soyeb Ganja** - [LinkedIN Profile](https://linkedin.com/in/soyeb-ganja), [GitHub Profile](https://github.com/soyebganja)


